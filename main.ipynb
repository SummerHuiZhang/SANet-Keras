{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import model_from_json\n",
    "from SANet import SANet\n",
    "import shutil\n",
    "from utils import load_img, gen_x_y, eval_loss, gen_paths, ssim_eucli_loss, random_cropping\n",
    "\n",
    "\n",
    "# Settings\n",
    "net = 'SANet'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "%matplotlib inline\n",
    "dataset = \"B\"\n",
    "LOSS = 'ssim_eucli_loss'\n",
    "LOSS_train = eval(LOSS)\n",
    "with_validation = False\n",
    "lr = 1e-4\n",
    "\n",
    "img_paths_test, img_paths_train = gen_paths(\n",
    "    path_file_root='data/paths_train_val_test',\n",
    "    dataset=dataset,\n",
    "    with_validation=with_validation\n",
    ")\n",
    "# img_paths_test, img_paths_train = img_paths_test[:10], img_paths_train[:10]\n",
    "if with_validation:\n",
    "    img_paths_train = list(set(img_paths_train) - set(img_paths_val))\n",
    "    x_val, y_val, img_paths_val = gen_x_y(img_paths_val, 'val')\n",
    "    print(len(x_val), len(y_val), len(img_paths_val))\n",
    "    x_test, y_test, img_paths_test = gen_x_y(img_paths_test, 'test')\n",
    "    print('Test data size:', len(x_test), len(y_test), len(img_paths_test))\n",
    "else:\n",
    "    x_val, y_val, img_paths_val = gen_x_y(img_paths_test[:16], 'test')\n",
    "    print('Validation data size:', len(x_val), len(y_val), len(img_paths_val))\n",
    "x_train, y_train, img_paths_train = gen_x_y(img_paths_train[:], 'train', augmentation_methods=['ori', 'flip'])\n",
    "print('Train data size:', len(x_train), len(y_train), len(img_paths_train))\n",
    "weights_dir = 'weights_' + dataset\n",
    "if os.path.exists(weights_dir):\n",
    "    shutil.rmtree(weights_dir)\n",
    "os.makedirs(weights_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = SANet(IN=False)\n",
    "model.summary()\n",
    "optimizer = Adam(lr=lr)\n",
    "model.compile(optimizer=optimizer, loss=LOSS_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Settings\n",
    "# model.load_weights('SANet_best.hdf5')\n",
    "if not os.path.exists(weights_dir):\n",
    "    os.makedirs(weights_dir)\n",
    "# Two ways to set the different parts of model trainable\n",
    "# Set different branches trainable seperatly(Each module has four branches)\n",
    "branches_untrainable = [\n",
    "    [2, 3, 4, 6, 7, 8, 11, 12, 13, 14, 15, 16, 18, 19, 20, 22, 23, 24, 27, 28, 29, 30, 31, 32, 34, 35, 36, 38, 39, 40, 43, 44, 45, 46, 47, 48, 50, 51, 52, 54, 55, 56],\n",
    "    [2, 3, 4, 6, 7, 8, 12, 13, 15, 16, 17, 19, 20, 22, 23, 24, 28, 29, 31, 32, 33, 35, 36, 37, 39, 40, 44, 45, 47, 48, 49, 51, 52, 53, 55, 56],\n",
    "    [1, 3, 4, 5, 7, 8, 11, 13, 14, 16, 17, 18, 20, 21, 22, 24, 27, 29, 30, 32, 33, 34, 36, 37, 38, 40, 43, 45, 46, 48, 49, 50, 52, 53, 54, 56],\n",
    "    [1, 2, 4, 5, 6, 8, 11, 12, 14, 15, 17, 18, 19, 21, 22, 23, 27, 28, 30, 31, 33, 34, 35, 37, 38, 39, 43, 44, 46, 47, 49, 50, 51, 53, 54, 55]\n",
    "]\n",
    "# Set differernt modules trainable 3 Inception-like module and the Decoder module trainable seperatly.\n",
    "branches_trainable = [\n",
    "    list(range(1, 4+1)),\n",
    "    list(range(5, 11+1)),\n",
    "    list(range(12, 18+1)),\n",
    "    list(range(19, 25+1)),\n",
    "    list(range(26, 33+1))\n",
    "]\n",
    "lossMAE = 1e5\n",
    "lossMDMD, lossMAPE, lossMSE = -1, -1, -1\n",
    "counter_train = 0\n",
    "mae = 1e5\n",
    "val_rate = 0.2\n",
    "lossesMDMD = []\n",
    "lossesMAE = []\n",
    "lossesMAPE = []\n",
    "lossesMSE = []\n",
    "path_val_display = img_paths_val[0]\n",
    "x_val_display = load_img(path_val_display)\n",
    "y_val_display = np.squeeze(y_val[0])\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "with open('./models/{}.json'.format(net), 'w') as fout:\n",
    "    fout.write(model.to_json())\n",
    "if dataset == 'A':\n",
    "    save_frequencies = [(90, 0.1), (80, 0.05), (95, 0.25)]\n",
    "else:\n",
    "    save_frequencies = [(30, 0.1), (16, 0.05), (32, 0.25)]\n",
    "\n",
    "if_train_seperatly = True\n",
    "if if_train_seperatly:\n",
    "    module_step = 1\n",
    "    epoch_train_seperatly = module_step * len(branches_untrainable) * 1\n",
    "    epoch_train = epoch_train_seperatly + 100\n",
    "else:\n",
    "    epoch_train = 200\n",
    "    \n",
    "\n",
    "# Training\n",
    "time_st = time.time()\n",
    "for epoch in range(epoch_train):\n",
    "    if if_train_seperatly:\n",
    "        trainable_choice = epoch % (module_step*len(branches_untrainable))\n",
    "        # Train modules seperatly to avoid output all zeros\n",
    "        if epoch < epoch_train_seperatly and trainable_choice in [0, module_step*1, module_step*2, module_step*3, module_step*4, module_step*5]:\n",
    "            branch_trainable = branches_trainable[trainable_choice]\n",
    "            for i in range(1, len(model.layers)):\n",
    "                if 'conv' in model.layers[i].name or 'activa' in model.layers[i].name or 'norm' in model.layers[i].name or 1:\n",
    "                    model.layers[i].trainable = False\n",
    "            for i in range(1, len(model.layers)):\n",
    "                idx_operator = int(model.layers[i].name.split('_')[-1])\n",
    "                if idx_operator in branch_trainable:\n",
    "                    model.layers[i].trainable = True\n",
    "            model.compile(optimizer=Adam(lr=lr), loss=LOSS_train)\n",
    "        elif epoch == epoch_train_seperatly:\n",
    "            for i in range(1, len(model.layers)):\n",
    "                model.layers[i].trainable = True\n",
    "            model.compile(optimizer=Adam(lr=lr/10), loss=LOSS_train)\n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    for i in range(len(x_train)):\n",
    "        if lossMAE < save_frequencies[0][0]:\n",
    "            val_rate = save_frequencies[0][1]\n",
    "            if lossMAE < save_frequencies[1][0]:\n",
    "                val_rate = save_frequencies[1][1]\n",
    "        if len(lossesMAE) > 50 and val_rate <= save_frequencies[-1][-1] and np.median(lossesMAE[-20]) > save_frequencies[-1][0]:\n",
    "            val_rate = save_frequencies[-1][-1]\n",
    "        x_, y_ = x_train[i], y_train[i]\n",
    "        model.fit(x_, y_, batch_size=1, verbose=0)\n",
    "#         x_crop, y_crop = random_cropping(x_, y_)\n",
    "#         model.fit(x_crop, y_crop, batch_size=1, verbose=0)\n",
    "#         x_flip, y_flip = x_[:, :, ::-1, :], y_[:, :, ::-1, :]\n",
    "#         x_flip_crop, y_flip_crop = random_cropping(x_flip, y_flip)\n",
    "#         model.fit(x_flip_crop, y_flip_crop, batch_size=1, verbose=0)\n",
    "        counter_train += 1\n",
    "        if counter_train % int(len(x_train)*val_rate) == 0:\n",
    "            # Calc loss\n",
    "            lossMDMD, lossMAE, lossMAPE, lossMSE = eval_loss(model, x_val, y_val)\n",
    "            lossesMDMD.append(lossMDMD)\n",
    "            lossesMAE.append(lossMAE)\n",
    "            lossesMAPE.append(lossMAPE)\n",
    "            lossesMSE.append(lossMSE)\n",
    "            lossMAE, lossMAPE, lossMDMD, lossMSE = round(lossMAE, 3), round(lossMAPE, 3), round(lossMDMD, 3), round(lossMSE, 3)\n",
    "            if (lossMAE < mae and epoch_train > 0) or lossMAE < save_frequencies[1][0] * 0.9:\n",
    "                mae = lossMAE\n",
    "                model.save_weights(\n",
    "                    os.path.join(weights_dir, '{}_MAE{}_MSE{}_MAPE{}_MDMD{}_epoch{}-{}.hdf5'.format(\n",
    "                        net, str(lossMAE), str(lossMSE), str(lossMAPE), str(lossMDMD), epoch, counter_train%len(x_train)\n",
    "                    ))\n",
    "                )\n",
    "                model.save_weights(os.path.join(weights_dir, '{}_best.hdf5'.format(net)))\n",
    "            if counter_train % (len(x_train)*2) == 0:\n",
    "                # show prediction\n",
    "                pred = np.squeeze(model.predict(np.expand_dims(x_val_display, axis=0)))\n",
    "                fg, (ax_x_ori, ax_y, ax_pred) = plt.subplots(1, 3, figsize=(20, 4))\n",
    "                ax_x_ori.imshow(cv2.cvtColor(cv2.imread(path_val_display), cv2.COLOR_BGR2RGB))\n",
    "                ax_x_ori.set_title('Original Image')\n",
    "                ax_y.imshow(y_val_display, cmap=plt.cm.jet)\n",
    "                ax_y.set_title('Ground_truth: ' + str(np.sum(y_val_display)))\n",
    "                ax_pred.imshow(pred, cmap=plt.cm.jet)\n",
    "                ax_pred.set_title('Prediction: ' + str(np.sum(pred)))\n",
    "                plt.suptitle('Loss = ' + str(lossMAE))\n",
    "                plt.show()\n",
    "            if counter_train % (len(x_train)*1) == 0 and (epoch+1) % (4) == 0:\n",
    "                # plot val_loss\n",
    "                plt.plot(lossesMDMD, 'r')\n",
    "                plt.plot(lossesMSE, 'c')\n",
    "                plt.plot(lossesMAE, 'b')\n",
    "                plt.plot(lossesMAPE, 'y')\n",
    "                plt.legend(['Loss_Density_Map_Distance', 'LossMSE', 'LossMAE', 'LossMAPE'])\n",
    "                plt.title('Loss')\n",
    "                plt.show()\n",
    "        time_now = time.time()\n",
    "        time_consuming = time_now - time_st\n",
    "        sys.stdout.write('In epoch {}_{}, with MAE={}, MSE={}, MAPE={}, MDMD={}, time consuming={}m-{}s\\r'.format(\n",
    "            epoch, counter_train%len(x_train), str(lossMAE), str(lossMSE), str(lossMAPE), str(lossMDMD),\n",
    "            int(time_consuming/60), int(time_consuming-int(time_consuming/60)*60)\n",
    "        ))\n",
    "        sys.stdout.flush()\n",
    "end_time_of_train = '_'.join('-'.join(time.ctime().split()).split(':'))\n",
    "MAE_min = str(round(np.min(lossesMAE), 3))\n",
    "shutil.move('weights_{}'.format(dataset), 'weights_{}_{}_bestMAE{}_{}'.format(dataset, LOSS, MAE_min, end_time_of_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_dir = 'losses_' + dataset\n",
    "if not os.path.exists(loss_dir):\n",
    "    os.makedirs(loss_dir)\n",
    "np.savetxt(os.path.join(loss_dir, 'loss_DMD.txt'), lossesMDMD)\n",
    "np.savetxt(os.path.join(loss_dir, 'loss_MAE.txt'), lossesMAE)\n",
    "np.savetxt(os.path.join(loss_dir, 'loss_MAPE.txt'), lossesMAPE)\n",
    "np.savetxt(os.path.join(loss_dir, 'loss_MSE.txt'), lossesMSE)\n",
    "plt.plot(lossesMDMD, 'r')\n",
    "plt.plot(lossesMAE, 'b')\n",
    "plt.plot(lossesMAPE, 'y')\n",
    "plt.plot(lossesMSE, 'c')\n",
    "plt.legend(['Loss_Density_Map_Distance', 'Loss_MAE', 'LossMAPE', 'LossMSE'])\n",
    "plt.title('Loss -- {} epochs'.format(epoch_train))\n",
    "plt.savefig('./loss_{}/loss_{}_{}.jpg'.format(dataset, dataset, end_time_of_train))\n",
    "plt.show()\n",
    "shutil.move('losses_{}'.format(dataset), 'losses_{}_{}_bestMAE{}_{}'.format(dataset, LOSS, MAE_min, end_time_of_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('weights_B/SANet_best.hdf5')\n",
    "pred = np.squeeze(model.predict(np.expand_dims(x_val_display, axis=0)))\n",
    "fg, (ax_x_ori, ax_y, ax_pred) = plt.subplots(1, 3, figsize=(20, 4))\n",
    "ax_x_ori.imshow(cv2.cvtColor(cv2.imread(path_val_display), cv2.COLOR_BGR2RGB))\n",
    "ax_x_ori.set_title('Original Image')\n",
    "ax_y.imshow(y_val_display, cmap=plt.cm.jet)\n",
    "ax_y.set_title('Ground_truth: ' + str(np.sum(y_val_display)))\n",
    "ax_pred.imshow(pred, cmap=plt.cm.jet)\n",
    "ax_pred.set_title('Prediction: ' + str(np.sum(pred)))\n",
    "plt.suptitle('Loss = ' + str(lossMAE))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
