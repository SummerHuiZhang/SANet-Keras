{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import model_from_json\n",
    "from SANet import SANet\n",
    "import shutil\n",
    "from utils import load_img, gen_x_y, eval_loss, gen_paths, ssim_eucli_loss, random_cropping\n",
    "\n",
    "\n",
    "# Settings\n",
    "net = 'SANet'\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "%matplotlib inline\n",
    "dataset = \"B\"\n",
    "LOSS = 'ssim_eucli_loss'\n",
    "LOSS_train = eval(LOSS)\n",
    "with_validation = False\n",
    "lr = 1e-4\n",
    "\n",
    "img_paths_test, img_paths_train = gen_paths(\n",
    "    path_file_root='data/paths_train_val_test',\n",
    "    dataset=dataset,\n",
    "    with_validation=with_validation\n",
    ")\n",
    "# img_paths_test, img_paths_train = img_paths_test[:10], img_paths_train[:10]\n",
    "if with_validation:\n",
    "    img_paths_train = list(set(img_paths_train) - set(img_paths_val))\n",
    "    x_val, y_val, img_paths_val = gen_x_y(img_paths_val, 'val')\n",
    "    print(len(x_val), len(y_val), len(img_paths_val))\n",
    "    x_test, y_test, img_paths_test = gen_x_y(img_paths_test, 'test')\n",
    "    print('Test data size:', len(x_test), len(y_test), len(img_paths_test))\n",
    "else:\n",
    "    x_val, y_val, img_paths_val = gen_x_y(img_paths_test[:16], 'test')\n",
    "    print('Validation data size:', len(x_val), len(y_val), len(img_paths_val))\n",
    "x_train, y_train, img_paths_train = gen_x_y(img_paths_train[:], 'train', augmentation_methods=['ori', 'flip'])\n",
    "print('Train data size:', len(x_train), len(y_train), len(img_paths_train))\n",
    "weights_dir = 'weights_' + dataset\n",
    "if os.path.exists(weights_dir):\n",
    "    shutil.rmtree(weights_dir)\n",
    "os.makedirs(weights_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "model = SANet(IN=False)\n",
    "model.summary()\n",
    "optimizer = Adam(lr=lr)\n",
    "model.compile(optimizer=optimizer, loss=LOSS_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Settings\n",
    "\n",
    "lossMAE = 1e5\n",
    "lossMDMD, lossMAPE, lossMSE = -1, -1, -1\n",
    "counter_train = 0\n",
    "mae = 1e5\n",
    "val_rate = 0.1\n",
    "lossesMDMD = []\n",
    "lossesMAE = []\n",
    "lossesMAPE = []\n",
    "lossesMSE = []\n",
    "path_val_display = img_paths_val[0]\n",
    "x_val_display = load_img(path_val_display)\n",
    "y_val_display = np.squeeze(y_val[0])\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "with open('./models/{}.json'.format(net), 'w') as fout:\n",
    "    fout.write(model.to_json())\n",
    "if dataset == 'A':\n",
    "    save_frequencies = [(90, 0.1), (80, 0.05), (95, 0.25)]\n",
    "else:\n",
    "    save_frequencies = [(11, 0.1), (10, 0.05), (12, 0.25)]\n",
    "epoch_train = 150\n",
    "\n",
    "# Training\n",
    "time_st = time.time()\n",
    "for epoch in range(epoch_train):\n",
    "    for i in range(len(x_train)):\n",
    "        if lossMAE < save_frequencies[0][0]:\n",
    "            val_rate = save_frequencies[0][1]\n",
    "            if lossMAE < save_frequencies[1][0]:\n",
    "                val_rate = save_frequencies[1][1]\n",
    "        if len(lossesMAE) > 100 and val_rate <= save_frequencies[-1][-1] and np.median(lossesMAE[-20]) > save_frequencies[-1][0]:\n",
    "            val_rate = save_frequencies[-1][-1]\n",
    "        # val_rate != save_frequencies[0][1] and val_rate != 0.25 and \n",
    "#         if len(lossesMDMD) > 11 and np.sum(np.array(lossesMDMD[-10:]) < min(lossesMDMD[:-10])) < 1:\n",
    "#             lr /= 10\n",
    "#             optimizer = Adam(lr=lr)\n",
    "#             model.compile(optimizer=optimizer, loss=LOSS_train)\n",
    "        x_, y_ = x_train[i], y_train[i]\n",
    "        model.fit(x_, y_, batch_size=1, verbose=0)\n",
    "#         x_crop, y_crop = random_cropping(x_, y_)\n",
    "#         model.fit(x_crop, y_crop, batch_size=1, verbose=0)\n",
    "#         x_flip, y_flip = x_[:, :, ::-1, :], y_[:, :, ::-1, :]\n",
    "#         x_flip_crop, y_flip_crop = random_cropping(x_flip, y_flip)\n",
    "#         model.fit(x_flip_crop, y_flip_crop, batch_size=1, verbose=0)\n",
    "        counter_train += 1\n",
    "        if counter_train % int(len(x_train)*val_rate) == 0:\n",
    "            # Calc loss\n",
    "            lossMDMD, lossMAE, lossMAPE, lossMSE = eval_loss(model, x_val, y_val)\n",
    "            lossesMDMD.append(lossMDMD)\n",
    "            lossesMAE.append(lossMAE)\n",
    "            lossesMAPE.append(lossMAPE)\n",
    "            lossesMSE.append(lossMSE)\n",
    "            lossMAE, lossMAPE, lossMDMD, lossMSE = round(lossMAE, 3), round(lossMAPE, 3), round(lossMDMD, 3), round(lossMSE, 3)\n",
    "            if (lossMAE < mae and epoch_train > 0) or lossMAE < save_frequencies[1][0] * 0.9:\n",
    "                mae = lossMAE\n",
    "                model.save_weights(\n",
    "                    os.path.join(weights_dir, '{}_MAE{}_MSE{}_MAPE{}_MDMD{}_epoch{}-{}.hdf5'.format(\n",
    "                        net, str(lossMAE), str(lossMSE), str(lossMAPE), str(lossMDMD), epoch, counter_train%len(x_train)\n",
    "                    ))\n",
    "                )\n",
    "                model.save_weights(os.path.join(weights_dir, '{}_best.hdf5'.format(net)))\n",
    "            if counter_train % (len(x_train)*10) == 0:\n",
    "                # show prediction\n",
    "                pred = np.squeeze(model.predict(np.expand_dims(x_val_display, axis=0)))\n",
    "                fg, (ax_x_ori, ax_y, ax_pred) = plt.subplots(1, 3, figsize=(20, 4))\n",
    "                ax_x_ori.imshow(cv2.cvtColor(cv2.imread(path_val_display), cv2.COLOR_BGR2RGB))\n",
    "                ax_x_ori.set_title('Original Image')\n",
    "                ax_y.imshow(y_val_display, cmap=plt.cm.jet)\n",
    "                ax_y.set_title('Ground_truth: ' + str(np.sum(y_val_display)))\n",
    "                ax_pred.imshow(pred, cmap=plt.cm.jet)\n",
    "                ax_pred.set_title('Prediction: ' + str(np.sum(pred)))\n",
    "                plt.suptitle('Loss = ' + str(lossMAE))\n",
    "                plt.show()\n",
    "                if (epoch+1) % (50) == 0:\n",
    "                    # plot val_loss\n",
    "                    plt.plot(lossesMDMD, 'r')\n",
    "                    plt.plot(lossesMAE, 'b')\n",
    "                    plt.plot(lossesMAPE, 'y')\n",
    "                    plt.plot(lossesMSE, 'c')\n",
    "                    plt.legend(['Loss_Density_Map_Distance', 'LossMAE', 'LossMAPE', 'LossMSE'])\n",
    "                    plt.title('Loss')\n",
    "                    plt.show()\n",
    "        time_now = time.time()\n",
    "        time_consuming = time_now - time_st\n",
    "        sys.stdout.write('In epoch {}_{}, with MAE={}, MSE={}, MAPE={}, MDMD={}, time consuming={}m-{}s\\r'.format(\n",
    "            epoch, counter_train%len(x_train), str(lossMAE), str(lossMSE), str(lossMAPE), str(lossMDMD),\n",
    "            int(time_consuming/60), int(time_consuming-int(time_consuming/60)*60)\n",
    "        ))\n",
    "        sys.stdout.flush()\n",
    "end_time_of_train = '_'.join('-'.join(time.ctime().split()).split(':'))\n",
    "MAE_min = str(round(np.min(lossesMAE), 3))\n",
    "shutil.move('weights_{}'.format(dataset), 'weights_{}_{}_bestMAE{}_{}'.format(dataset, LOSS, MAE_min, end_time_of_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_dir = 'losses_' + dataset\n",
    "if not os.path.exists(loss_dir):\n",
    "    os.makedirs(loss_dir)\n",
    "np.savetxt(os.path.join(loss_dir, 'loss_DMD.txt'), lossesMDMD)\n",
    "np.savetxt(os.path.join(loss_dir, 'loss_MAE.txt'), lossesMAE)\n",
    "np.savetxt(os.path.join(loss_dir, 'loss_MAPE.txt'), lossesMAPE)\n",
    "np.savetxt(os.path.join(loss_dir, 'loss_MSE.txt'), lossesMSE)\n",
    "plt.plot(lossesMDMD, 'r')\n",
    "plt.plot(lossesMAE, 'b')\n",
    "plt.plot(lossesMAPE, 'y')\n",
    "plt.plot(lossesMSE, 'c')\n",
    "plt.legend(['Loss_Density_Map_Distance', 'Loss_MAE', 'LossMAPE', 'LossMSE'])\n",
    "plt.title('Loss -- {} epochs'.format(epoch_train))\n",
    "plt.savefig('./loss_{}/loss_{}_{}.jpg'.format(dataset, dataset, end_time_of_train))\n",
    "plt.show()\n",
    "shutil.move('losses_{}'.format(dataset), 'losses_{}_{}_bestMAE{}_{}'.format(dataset, LOSS, MAE_min, end_time_of_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('weights_B/SANet_best.hdf5')\n",
    "pred = np.squeeze(model.predict(np.expand_dims(x_val_display, axis=0)))\n",
    "fg, (ax_x_ori, ax_y, ax_pred) = plt.subplots(1, 3, figsize=(20, 4))\n",
    "ax_x_ori.imshow(cv2.cvtColor(cv2.imread(path_val_display), cv2.COLOR_BGR2RGB))\n",
    "ax_x_ori.set_title('Original Image')\n",
    "ax_y.imshow(y_val_display, cmap=plt.cm.jet)\n",
    "ax_y.set_title('Ground_truth: ' + str(np.sum(y_val_display)))\n",
    "ax_pred.imshow(pred, cmap=plt.cm.jet)\n",
    "ax_pred.set_title('Prediction: ' + str(np.sum(pred)))\n",
    "plt.suptitle('Loss = ' + str(lossMAE))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('./SANet_MAE15.316_MSE29.441_MAPE0.11_MDMD125.635_epoch70-200.hdf5')\n",
    "lossMDMD, lossMAE, lossMAPE, lossMSE = eval_loss(model, x_val, y_val)\n",
    "print(lossMDMD, lossMAE, lossMAPE, lossMSE)\n",
    "with open('SANet_noIN.json'.format(net), 'w') as fout:\n",
    "    fout.write(model.to_json())\n",
    "model.save_weights('SANet_noIN_MAE14.32_MSE22.88_MAPE12.22_MDMD110.62_epoch7-240.hdf5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
